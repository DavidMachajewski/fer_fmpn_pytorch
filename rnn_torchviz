digraph {
	graph [size="55.65,55.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2528909818360 [label="
 (8, 7)" fillcolor=darkolivegreen1]
	2528903984456 [label=SoftmaxBackward]
	2528924833224 -> 2528903984456
	2528924833224 [label=AddmmBackward]
	2528924833544 -> 2528924833224
	2528924694632 [label="resnet.13.bias
 (7)" fillcolor=lightblue]
	2528924694632 -> 2528924833544
	2528924833544 [label=AccumulateGrad]
	2528924833672 -> 2528924833224
	2528924833672 [label=ViewBackward]
	2528924833736 -> 2528924833672
	2528924833736 [label=MulBackward0]
	2528924833864 -> 2528924833736
	2528924833864 [label=MeanBackward1]
	2528924833992 -> 2528924833864
	2528924833992 [label=ReluBackward1]
	2528924834120 -> 2528924833992
	2528924834120 [label=AddBackward0]
	2528924834248 -> 2528924834120
	2528924834248 [label=NativeBatchNormBackward]
	2528924834440 -> 2528924834248
	2528924834440 [label=MkldnnConvolutionBackward]
	2528924834696 -> 2528924834440
	2528924834696 [label=ReluBackward1]
	2528924834888 -> 2528924834696
	2528924834888 [label=NativeBatchNormBackward]
	2528924835016 -> 2528924834888
	2528924835016 [label=MkldnnConvolutionBackward]
	2528924834312 -> 2528924835016
	2528924834312 [label=ReluBackward1]
	2528924835400 -> 2528924834312
	2528924835400 [label=AddBackward0]
	2528924835528 -> 2528924835400
	2528924835528 [label=NativeBatchNormBackward]
	2528924835720 -> 2528924835528
	2528924835720 [label=MkldnnConvolutionBackward]
	2528924860616 -> 2528924835720
	2528924860616 [label=ReluBackward1]
	2528924860808 -> 2528924860616
	2528924860808 [label=NativeBatchNormBackward]
	2528924860936 -> 2528924860808
	2528924860936 [label=MkldnnConvolutionBackward]
	2528924861192 -> 2528924860936
	2528924861192 [label=ReluBackward1]
	2528924861384 -> 2528924861192
	2528924861384 [label=AddBackward0]
	2528924861512 -> 2528924861384
	2528924861512 [label=NativeBatchNormBackward]
	2528924861704 -> 2528924861512
	2528924861704 [label=MkldnnConvolutionBackward]
	2528924861960 -> 2528924861704
	2528924861960 [label=ReluBackward1]
	2528924862152 -> 2528924861960
	2528924862152 [label=NativeBatchNormBackward]
	2528924862280 -> 2528924862152
	2528924862280 [label=MkldnnConvolutionBackward]
	2528924861576 -> 2528924862280
	2528924861576 [label=ReluBackward1]
	2528924862664 -> 2528924861576
	2528924862664 [label=AddBackward0]
	2528924862792 -> 2528924862664
	2528924862792 [label=NativeBatchNormBackward]
	2528924862984 -> 2528924862792
	2528924862984 [label=MkldnnConvolutionBackward]
	2528924863368 -> 2528924862984
	2528924863368 [label=ReluBackward1]
	2528924863752 -> 2528924863368
	2528924863752 [label=NativeBatchNormBackward]
	2528924863944 -> 2528924863752
	2528924863944 [label=MkldnnConvolutionBackward]
	2528924864392 -> 2528924863944
	2528924864392 [label=ReluBackward1]
	2528924864840 -> 2528924864392
	2528924864840 [label=AddBackward0]
	2528924865096 -> 2528924864840
	2528924865096 [label=NativeBatchNormBackward]
	2528924865416 -> 2528924865096
	2528924865416 [label=MkldnnConvolutionBackward]
	2528924865864 -> 2528924865416
	2528924865864 [label=ReluBackward1]
	2528924866248 -> 2528924865864
	2528924866248 [label=NativeBatchNormBackward]
	2528924866440 -> 2528924866248
	2528924866440 [label=MkldnnConvolutionBackward]
	2528924865288 -> 2528924866440
	2528924865288 [label=ReluBackward1]
	2528924867208 -> 2528924865288
	2528924867208 [label=AddBackward0]
	2528924867464 -> 2528924867208
	2528924867464 [label=NativeBatchNormBackward]
	2528924867784 -> 2528924867464
	2528924867784 [label=MkldnnConvolutionBackward]
	2528924868232 -> 2528924867784
	2528924868232 [label=ReluBackward1]
	2528924872776 -> 2528924868232
	2528924872776 [label=NativeBatchNormBackward]
	2528924872968 -> 2528924872776
	2528924872968 [label=MkldnnConvolutionBackward]
	2528924873416 -> 2528924872968
	2528924873416 [label=ReluBackward1]
	2528924873800 -> 2528924873416
	2528924873800 [label=AddBackward0]
	2528924874056 -> 2528924873800
	2528924874056 [label=NativeBatchNormBackward]
	2528924874376 -> 2528924874056
	2528924874376 [label=MkldnnConvolutionBackward]
	2528924874824 -> 2528924874376
	2528924874824 [label=ReluBackward1]
	2528924875208 -> 2528924874824
	2528924875208 [label=NativeBatchNormBackward]
	2528924875400 -> 2528924875208
	2528924875400 [label=MkldnnConvolutionBackward]
	2528924874248 -> 2528924875400
	2528924874248 [label=ReluBackward1]
	2528924876168 -> 2528924874248
	2528924876168 [label=AddBackward0]
	2528924876424 -> 2528924876168
	2528924876424 [label=NativeBatchNormBackward]
	2528924876744 -> 2528924876424
	2528924876744 [label=MkldnnConvolutionBackward]
	2528924877256 -> 2528924876744
	2528924877256 [label=ReluBackward1]
	2528924877640 -> 2528924877256
	2528924877640 [label=NativeBatchNormBackward]
	2528924877832 -> 2528924877640
	2528924877832 [label=MkldnnConvolutionBackward]
	2528924876616 -> 2528924877832
	2528924876616 [label=MaxPool2DWithIndicesBackward]
	2528924878600 -> 2528924876616
	2528924878600 [label=MkldnnConvolutionBackward]
	2528924878984 -> 2528924878600
	2528909695960 [label="resnet.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2528909695960 -> 2528924878984
	2528924878984 [label=AccumulateGrad]
	2528924878408 -> 2528924877832
	2528909696120 [label="resnet.2.convx_1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2528909696120 -> 2528924878408
	2528924878408 [label=AccumulateGrad]
	2528924878024 -> 2528924877640
	2528909695880 [label="resnet.2.bn_1.weight
 (64)" fillcolor=lightblue]
	2528909695880 -> 2528924878024
	2528924878024 [label=AccumulateGrad]
	2528924878152 -> 2528924877640
	2528909696440 [label="resnet.2.bn_1.bias
 (64)" fillcolor=lightblue]
	2528909696440 -> 2528924878152
	2528924878152 [label=AccumulateGrad]
	2528924877448 -> 2528924876744
	2528909696280 [label="resnet.2.convx_2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2528909696280 -> 2528924877448
	2528924877448 [label=AccumulateGrad]
	2528924877000 -> 2528924876424
	2528909696840 [label="resnet.2.bn_2.weight
 (64)" fillcolor=lightblue]
	2528909696840 -> 2528924877000
	2528924877000 [label=AccumulateGrad]
	2528924877128 -> 2528924876424
	2528909696920 [label="resnet.2.bn_2.bias
 (64)" fillcolor=lightblue]
	2528909696920 -> 2528924877128
	2528924877128 [label=AccumulateGrad]
	2528924876616 -> 2528924876168
	2528924875976 -> 2528924875400
	2528909742712 [label="resnet.3.convx_1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2528909742712 -> 2528924875976
	2528924875976 [label=AccumulateGrad]
	2528924875592 -> 2528924875208
	2528909742632 [label="resnet.3.bn_1.weight
 (64)" fillcolor=lightblue]
	2528909742632 -> 2528924875592
	2528924875592 [label=AccumulateGrad]
	2528924875720 -> 2528924875208
	2528909743032 [label="resnet.3.bn_1.bias
 (64)" fillcolor=lightblue]
	2528909743032 -> 2528924875720
	2528924875720 [label=AccumulateGrad]
	2528924875016 -> 2528924874376
	2528909742872 [label="resnet.3.convx_2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2528909742872 -> 2528924875016
	2528924875016 [label=AccumulateGrad]
	2528924874568 -> 2528924874056
	2528909743352 [label="resnet.3.bn_2.weight
 (64)" fillcolor=lightblue]
	2528909743352 -> 2528924874568
	2528924874568 [label=AccumulateGrad]
	2528924874696 -> 2528924874056
	2528909743432 [label="resnet.3.bn_2.bias
 (64)" fillcolor=lightblue]
	2528909743432 -> 2528924874696
	2528924874696 [label=AccumulateGrad]
	2528924874248 -> 2528924873800
	2528924873608 -> 2528924872968
	2528909744072 [label="resnet.4.convx_1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2528909744072 -> 2528924873608
	2528924873608 [label=AccumulateGrad]
	2528924873160 -> 2528924872776
	2528909743992 [label="resnet.4.bn_1.weight
 (128)" fillcolor=lightblue]
	2528909743992 -> 2528924873160
	2528924873160 [label=AccumulateGrad]
	2528924873288 -> 2528924872776
	2528909744392 [label="resnet.4.bn_1.bias
 (128)" fillcolor=lightblue]
	2528909744392 -> 2528924873288
	2528924873288 [label=AccumulateGrad]
	2528924868424 -> 2528924867784
	2528909744232 [label="resnet.4.convx_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2528909744232 -> 2528924868424
	2528924868424 [label=AccumulateGrad]
	2528924867976 -> 2528924867464
	2528909744712 [label="resnet.4.bn_2.weight
 (128)" fillcolor=lightblue]
	2528909744712 -> 2528924867976
	2528924867976 [label=AccumulateGrad]
	2528924868104 -> 2528924867464
	2528909744792 [label="resnet.4.bn_2.bias
 (128)" fillcolor=lightblue]
	2528909744792 -> 2528924868104
	2528924868104 [label=AccumulateGrad]
	2528924867656 -> 2528924867208
	2528924867656 [label=MkldnnConvolutionBackward]
	2528924873416 -> 2528924867656
	2528924868168 -> 2528924867656
	2528909745192 [label="resnet.4.downsample.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2528909745192 -> 2528924868168
	2528924868168 [label=AccumulateGrad]
	2528924868552 -> 2528924867656
	2528909745272 [label="resnet.4.downsample.bias
 (128)" fillcolor=lightblue]
	2528909745272 -> 2528924868552
	2528924868552 [label=AccumulateGrad]
	2528924867016 -> 2528924866440
	2528909745432 [label="resnet.5.convx_1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2528909745432 -> 2528924867016
	2528924867016 [label=AccumulateGrad]
	2528924866632 -> 2528924866248
	2528909745352 [label="resnet.5.bn_1.weight
 (128)" fillcolor=lightblue]
	2528909745352 -> 2528924866632
	2528924866632 [label=AccumulateGrad]
	2528924866760 -> 2528924866248
	2528909745752 [label="resnet.5.bn_1.bias
 (128)" fillcolor=lightblue]
	2528909745752 -> 2528924866760
	2528924866760 [label=AccumulateGrad]
	2528924866056 -> 2528924865416
	2528909745592 [label="resnet.5.convx_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2528909745592 -> 2528924866056
	2528924866056 [label=AccumulateGrad]
	2528924865608 -> 2528924865096
	2528909746072 [label="resnet.5.bn_2.weight
 (128)" fillcolor=lightblue]
	2528909746072 -> 2528924865608
	2528924865608 [label=AccumulateGrad]
	2528924865736 -> 2528924865096
	2528909815880 [label="resnet.5.bn_2.bias
 (128)" fillcolor=lightblue]
	2528909815880 -> 2528924865736
	2528924865736 [label=AccumulateGrad]
	2528924865288 -> 2528924864840
	2528924864648 -> 2528924863944
	2528909816520 [label="resnet.6.convx_1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2528909816520 -> 2528924864648
	2528924864648 [label=AccumulateGrad]
	2528924864136 -> 2528924863752
	2528909816440 [label="resnet.6.bn_1.weight
 (256)" fillcolor=lightblue]
	2528909816440 -> 2528924864136
	2528924864136 [label=AccumulateGrad]
	2528924864264 -> 2528924863752
	2528909816840 [label="resnet.6.bn_1.bias
 (256)" fillcolor=lightblue]
	2528909816840 -> 2528924864264
	2528924864264 [label=AccumulateGrad]
	2528924863560 -> 2528924862984
	2528909816680 [label="resnet.6.convx_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2528909816680 -> 2528924863560
	2528924863560 [label=AccumulateGrad]
	2528924863112 -> 2528924862792
	2528909817160 [label="resnet.6.bn_2.weight
 (256)" fillcolor=lightblue]
	2528909817160 -> 2528924863112
	2528924863112 [label=AccumulateGrad]
	2528924863240 -> 2528924862792
	2528909817240 [label="resnet.6.bn_2.bias
 (256)" fillcolor=lightblue]
	2528909817240 -> 2528924863240
	2528924863240 [label=AccumulateGrad]
	2528924862856 -> 2528924862664
	2528924862856 [label=MkldnnConvolutionBackward]
	2528924864392 -> 2528924862856
	2528924863304 -> 2528924862856
	2528909817640 [label="resnet.6.downsample.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2528909817640 -> 2528924863304
	2528924863304 [label=AccumulateGrad]
	2528924863688 -> 2528924862856
	2528909817720 [label="resnet.6.downsample.bias
 (256)" fillcolor=lightblue]
	2528909817720 -> 2528924863688
	2528924863688 [label=AccumulateGrad]
	2528924862536 -> 2528924862280
	2528909817880 [label="resnet.7.convx_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2528909817880 -> 2528924862536
	2528924862536 [label=AccumulateGrad]
	2528924862344 -> 2528924862152
	2528909817800 [label="resnet.7.bn_1.weight
 (256)" fillcolor=lightblue]
	2528909817800 -> 2528924862344
	2528924862344 [label=AccumulateGrad]
	2528924862408 -> 2528924862152
	2528909818200 [label="resnet.7.bn_1.bias
 (256)" fillcolor=lightblue]
	2528909818200 -> 2528924862408
	2528924862408 [label=AccumulateGrad]
	2528924862024 -> 2528924861704
	2528909818040 [label="resnet.7.convx_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2528909818040 -> 2528924862024
	2528924862024 [label=AccumulateGrad]
	2528924861768 -> 2528924861512
	2528909818520 [label="resnet.7.bn_2.weight
 (256)" fillcolor=lightblue]
	2528909818520 -> 2528924861768
	2528924861768 [label=AccumulateGrad]
	2528924861832 -> 2528924861512
	2528909818600 [label="resnet.7.bn_2.bias
 (256)" fillcolor=lightblue]
	2528909818600 -> 2528924861832
	2528924861832 [label=AccumulateGrad]
	2528924861576 -> 2528924861384
	2528924861256 -> 2528924860936
	2528909819240 [label="resnet.8.convx_1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2528909819240 -> 2528924861256
	2528924861256 [label=AccumulateGrad]
	2528924861000 -> 2528924860808
	2528909819160 [label="resnet.8.bn_1.weight
 (512)" fillcolor=lightblue]
	2528909819160 -> 2528924861000
	2528924861000 [label=AccumulateGrad]
	2528924861064 -> 2528924860808
	2528909819560 [label="resnet.8.bn_1.bias
 (512)" fillcolor=lightblue]
	2528909819560 -> 2528924861064
	2528924861064 [label=AccumulateGrad]
	2528924860680 -> 2528924835720
	2528909819400 [label="resnet.8.convx_2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2528909819400 -> 2528924860680
	2528924860680 [label=AccumulateGrad]
	2528924835784 -> 2528924835528
	2528924692552 [label="resnet.8.bn_2.weight
 (512)" fillcolor=lightblue]
	2528924692552 -> 2528924835784
	2528924835784 [label=AccumulateGrad]
	2528924860488 -> 2528924835528
	2528924692632 [label="resnet.8.bn_2.bias
 (512)" fillcolor=lightblue]
	2528924692632 -> 2528924860488
	2528924860488 [label=AccumulateGrad]
	2528924835592 -> 2528924835400
	2528924835592 [label=MkldnnConvolutionBackward]
	2528924861192 -> 2528924835592
	2528924860552 -> 2528924835592
	2528924693032 [label="resnet.8.downsample.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2528924693032 -> 2528924860552
	2528924860552 [label=AccumulateGrad]
	2528924860744 -> 2528924835592
	2528924693112 [label="resnet.8.downsample.bias
 (512)" fillcolor=lightblue]
	2528924693112 -> 2528924860744
	2528924860744 [label=AccumulateGrad]
	2528924835272 -> 2528924835016
	2528924693272 [label="resnet.9.convx_1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2528924693272 -> 2528924835272
	2528924835272 [label=AccumulateGrad]
	2528924835080 -> 2528924834888
	2528924693192 [label="resnet.9.bn_1.weight
 (512)" fillcolor=lightblue]
	2528924693192 -> 2528924835080
	2528924835080 [label=AccumulateGrad]
	2528924835144 -> 2528924834888
	2528924693592 [label="resnet.9.bn_1.bias
 (512)" fillcolor=lightblue]
	2528924693592 -> 2528924835144
	2528924835144 [label=AccumulateGrad]
	2528924834760 -> 2528924834440
	2528924693432 [label="resnet.9.convx_2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2528924693432 -> 2528924834760
	2528924834760 [label=AccumulateGrad]
	2528924834504 -> 2528924834248
	2528924693912 [label="resnet.9.bn_2.weight
 (512)" fillcolor=lightblue]
	2528924693912 -> 2528924834504
	2528924834504 [label=AccumulateGrad]
	2528924834568 -> 2528924834248
	2528924693992 [label="resnet.9.bn_2.bias
 (512)" fillcolor=lightblue]
	2528924693992 -> 2528924834568
	2528924834568 [label=AccumulateGrad]
	2528924834312 -> 2528924834120
	2528924833608 -> 2528924833224
	2528924833608 [label=TBackward]
	2528924833416 -> 2528924833608
	2528924694552 [label="resnet.13.weight
 (7, 512)" fillcolor=lightblue]
	2528924694552 -> 2528924833416
	2528924833416 [label=AccumulateGrad]
	2528903984456 -> 2528909818360
}
